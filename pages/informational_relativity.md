title: On the Relativity of Information
subtitle: ' '
date: 2014-2-1
tags: [information-theory, language, communication]

Among popularized views of information theory there is a recurring theme that
information is on the rise as an absolute quantity to be measured in the world.
A historical view of the subject paints a picture in which the essential
properties of a long list of phenomena in the world, are really just
informational properties, upon coming into focus. A genome is a good example
(though natural language, or physics might be equally apt), in that when we see
the operation of the genome through its most useful lens, it apears to us as a
sequence of bits.  We may sometimes see it as a chemical system, or a mechanical
system, or even a quantum system, but those views are separated from the
important level of explanation by their inability to concisely capture the
phenomenon that appears to be causally relevant. I wish to humbly point out (I
don't think this is particularly clever on my part) that this connection between
an informational view and a practical view is not incidental or contingent, but
that they are bound together by the fundamental role of language in human
knowledge.

By language, I mean an expansive set of signals for which we have a special
creativty and to which we have a special sensitivity. (That's a pretty vague
definition of langauge, but the details are not essential here) The pieces of
language that I think are essential for explaining our sense of the importance
of information theory, are the tools we use for making one experience connect to
other experiences. For an event to ever have meaning, it must find some way to
affect our physical or mental life in some other way. In the case of memory or
experience, tt's not that we reproduce the event, but that it is somehow
causally relevant for some mind state, later on. This is not an easy thing to
do, as there are plenty of things happening in a mind that get ignored, or lost.
In order to have a significant effect, you have to leverage some existing
amplification or storage system.

This system we might imagine is the causal network that underpins the presence
of symbolism in the brain. If an event is to have some signficant effect on the
brain, it cannot merely displace any given electron. It has to make its way into
whatever sensitive dynamical system that serves as the basis for symbolic
thinking (and even thinking that doesn't feel symbolic, but which seems to have
symbolic structure upon closer inspection).

In this (admittedly far-fetched and vague) view, my motivating question can be
stated: how does such a symbolic system change the things to which it is
sensitive? The picture I would advocate is one where sensitivity to new patterns
must somehow be translated in the old patterns. I won't rule out the scenario
where new patterns may come to stand as first rate symbols. However, the
integration of new symbols relies on forging a connection with extant ones.
This really should be an innocuos claim: in order to understand most things we
need some context.

The reason all of this matters when we talk about information, is that the
elegance of information theory is just a statement about the way humans interact
with their environment, not an objective feature of a system in question. We use
information as a way to capture the properties of our communcation channels with
the world. If we can make sense of a system while only exchanging a few bits,
then that system has a simple informational representation. If a system requires
many many bits in order to usefully predict, then we might say that such a
system has complex information processing dynamics. The point of these
(hopefully natural) syllogisms is to show that it has nothing to do with the
system under inspection, but about the relationship between the observer and the
and that system.

If you're willing to grant that our knowledge about the world is mediated by
some symbolic representation, and that communication with a symbolic system fits
neatly into the purview of information theory, then we are roughly in agreement.
My goal so far has only been to recast evidence about the centrality of
information theory in the external world, into evidence about how a symbolic
system, like a mind, works.  The next point of interest is whether the question
of objective information holds up under this view.

Of course, the formulas for various mathematical definitions of information are
still perfectly consistent models, but do they respect the intent of
formalizing information, now that is might be better studied as a feature of a
symbolic system? Surely, the patterns identified by an information-level
perspective are useful and real-seeming, but don't they always rest upon some
strict formalization? If we want to talk about the information of written
language, we wind up heavily relying on letters or words, and for genes we use
abstract chemical types. The issue is not that these are somehow illegitimate
symbols, but the fact they are symbols. They only help if you already understand
the rules and assumptions which make them useful.

The issue raised by supposedly symbolic foundations, if you will, is that we
need to start looking at the informational properties of the symbolic system in
which we framed our original information theoretic statements. The fact that
information theory tends to thrive in contexts with well-defined formal models,
is a consequence of this same point. Formal languages help standardize the way
we look at the domains which they purportedly describe, but they always rely on
a separate form of understanding by which we connect them to the rest of our
knowledge. So, it is perfectly valid to talk about objective information within
formal langauges, but it is less clear to me that such talk makes sense in their
absence, and it is hard to imagine a formal-langauge bearing modal necessity.

Returning to our amplification and storage metaphor for a mind, can we draw the
line between the mind and the world? In any particular case, we might be able to
specify parts of the conceptual system which are internal, and part which are
external, but it seems hardly likely that the picture would be identical across
individuals. On this view, if two people have two different ways of making sense
of the world, why should we expect the informational aspects of the external
phenomena to match? Poetically, we communicate with the world using a code that
is our own private language. The And the details of our private language
determine the details of our external langauge. Bringing it back to something
that other people talk about sometimes, consider Kolmogorov complexity. When we
given an algorithm for creating some pattern, we do it in a formal language. The
first point which seems to vulnerable to claims of relativity, is the choice of
formal language.  Wouldn't a java version be longer than the haskell version?

We might assure ourselves that if we consider only the important logical aspects
of each program, they are roughly equivalent. But would they be exactly
equivalent? What about the fact that programming languages tend to rest upon
certain assumptions, and exist with various "paradigms"? Won't these need to be
encoded along with the program? The traditional work on this has been done in
the context of Turing machines, in which the formal language is well-defined.
But this should smell suspicious, as the very conceptual framework of turing
machines is useless without the appropriate understanding of its rules (though
admittedly they are brief, in the scheme of rules). The point is that aside from
serving as a consistent currency, turing machines are just another set of rules
which we must first grasp in order to make sense of whatever information we
encode with those rules. The binary encoding of a turing machine probably
doesn't look particularly interesting without a couple pages of text explaining
how to decode it. And the explanation will have to be a lot longer if the person
has never studied theoretical computer science. My goal is to bring some
appreciation to these related pieces of information, and suggest that we are
fooling ourselves if we focus only on the informational content *within* a
formal system.

All of this is meant to imply that information can only be well defined, either
in the context of a particular formal system, or perhaps in the context of a
particular mind (for which we already have a variety of formal system).
